{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183556e1-2124-43db-9b49-918c4ef52f7b",
   "metadata": {},
   "source": [
    "# HWIV\n",
    "\n",
    "Bixuan LIU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6adffdf-a306-4214-86a7-98b131c83bf3",
   "metadata": {},
   "source": [
    "## I. NN Model for 1-dimensional time series data\n",
    "In this section, I constructed an NN model with 1 hidden layer and 5 nodes to forecast Number of Unemployed (umply) in Luxembourg. And compare the results with the ARIMA model in HWII."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a491a2c1-6e60-4159-ba4b-8fde1d922a62",
   "metadata": {},
   "source": [
    "### 1. Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d2deab5-bce1-47b1-8305-3c7d6aedf51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019df591-e93e-487a-b8d5-48ce1d6145f7",
   "metadata": {},
   "source": [
    "### 2. Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a79a269-36be-4556-b155-678fcafa49ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1  # One-dimensional time series data\n",
    "hidden_size = 5  # Number of nodes in the hidden layer\n",
    "output_size = 1  # Output size (regression)\n",
    "\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76529d0-3df3-477e-b644-c42a084eadf5",
   "metadata": {},
   "source": [
    "### 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeb80d06-f552-4556-a811-fede2efd7a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date         umply            pop\n",
      "0   1995-01-01   4868.757781  171547.891390\n",
      "1   1995-02-01   4808.390434  171880.830559\n",
      "2   1995-03-01   4703.403744  172197.741094\n",
      "3   1995-04-01   4365.696555  171821.691070\n",
      "4   1995-05-01   4168.846510  172111.474364\n",
      "..         ...           ...            ...\n",
      "339 2023-04-01  15330.000000  308689.287139\n",
      "340 2023-05-01  15188.000000  308891.139093\n",
      "341 2023-06-01  15333.000000  309476.907263\n",
      "342 2023-07-01  16111.000000  307174.983768\n",
      "343 2023-08-01  16056.000000  306380.562733\n",
      "\n",
      "[344 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(\"HWIV_data_liu.xlsx\")\n",
    "df.rename(columns={'Time period': 'date', '9. Number of Unemployed': 'umply', '10. Active Population': 'pop'}, inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd66e0f-d169-46a9-946e-695d20c7a44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  umply_gr    pop_gr\n",
      "0   1996-01-01  0.068464  0.032177\n",
      "1   1996-02-01  0.072416  0.029055\n",
      "2   1996-03-01  0.053199  0.028199\n",
      "3   1996-04-01  0.109018  0.031830\n",
      "4   1996-05-01  0.107450  0.027202\n",
      "..         ...       ...       ...\n",
      "327 2023-04-01  0.074357  0.025367\n",
      "328 2023-05-01  0.089058  0.024345\n",
      "329 2023-06-01  0.124285  0.024101\n",
      "330 2023-07-01  0.129883  0.023301\n",
      "331 2023-08-01  0.134459  0.022038\n",
      "\n",
      "[332 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the data into yearly growth rates\n",
    "df['umply_gr'] = (df['umply'] - df['umply'].shift(12)) / df['umply'].shift(12)\n",
    "df['pop_gr'] = (df['pop'] - df['pop'].shift(12)) / df['pop'].shift(12)\n",
    "\n",
    "df_gr = df.loc[12:, ['date', 'umply_gr', 'pop_gr']].reset_index(drop=True)\n",
    "\n",
    "print(df_gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07cdb048-d5ff-47f8-8d8f-b320b9d3946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the split point based on the length of the DataFrame\n",
    "split_point = int(0.8 * len(df_gr))\n",
    "\n",
    "# Split the time series data\n",
    "train_data = df_gr['umply_gr'].iloc[:split_point]\n",
    "test_data = df_gr['umply_gr'].iloc[split_point:]\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "train_data_torch = torch.FloatTensor(train_data.values).view(-1, 1)\n",
    "test_data_torch = torch.FloatTensor(test_data.values).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb6eb50-79fe-435d-9a5e-f4fd36c999c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0086\n",
      "Epoch [200/1000], Loss: 0.0052\n",
      "Epoch [300/1000], Loss: 0.0035\n",
      "Epoch [400/1000], Loss: 0.0022\n",
      "Epoch [500/1000], Loss: 0.0012\n",
      "Epoch [600/1000], Loss: 0.0005\n",
      "Epoch [700/1000], Loss: 0.0002\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(train_data_torch)\n",
    "    loss = criterion(outputs, train_data_torch)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db180bbc-3e2e-449a-9939-146fc1cdde27",
   "metadata": {},
   "source": [
    "### 4. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f774a4a-5812-49c0-a1b3-6a229391f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize an array to store the forecasted values\n",
    "    forecasted_values = []\n",
    "\n",
    "    # Iterate through the test data one step at a time\n",
    "    for i in range(len(test_data_torch) - 1):\n",
    "        input_step = test_data_torch[:i+1]  # Include data up to the current step\n",
    "        output_step = model(input_step)\n",
    "        forecasted_values.append(output_step[-1].item())  # Take the last prediction\n",
    "\n",
    "    # Convert the forecasted values to a PyTorch tensor\n",
    "    forecasted_values_tensor = torch.Tensor(forecasted_values)\n",
    "\n",
    "    # Reshape the forecasted values tensor to match the shape of the target data\n",
    "    forecasted_values_tensor = forecasted_values_tensor.view(-1, 1)\n",
    "\n",
    "    # Calculate the MSE for the one-step-ahead forecast\n",
    "    mse_one_step_ahead = criterion(forecasted_values_tensor, test_data_torch[1:])\n",
    "    print(f'\\nMean Squared Error for One-Step-Ahead Forecast: {mse_one_step_ahead.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755db60f-f4ff-4a45-838c-ddc5bf814fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_data_torch[1:], label='True Values', marker='o')\n",
    "plt.plot(forecasted_values, label='Forecasted Values', linestyle='dashed', marker='o')\n",
    "plt.title('1-Step-Ahead Expanding-Window Forecast')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1909681-9c35-4708-8da3-64094a0f5b9d",
   "metadata": {},
   "source": [
    "### 5. Compare with ARIMA(4,0,0)\n",
    "Note: For details about the ARIMA model, please refer to HWII_analysis_liu.rmd. Here I only quote the results.\n",
    "\n",
    "RMSFE: \n",
    "NN model: 0.0073 ; \n",
    "ARIMA model: 0.069015\n",
    "\n",
    "NN model has a smaller RMSFE. That's because comparing to ARIMA model, NN model is more able to capture the complex internal relations inside the time series. But it's computationally heavier. In this HW, I used 1000 epochs to reach this nice result. If the number of epochs decrease, the performance of NN model will surely be much worse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc74cc9-c8ad-408a-a1fa-1068e70b1fa3",
   "metadata": {},
   "source": [
    "## II. NN Model for multi-dimensional time series data\n",
    "In this section, I constructed an NN model with again 1 hidden layer and 5 nodes to forecast Number of Unemployed (umply) and Active Population (pop) in Luxembourg. And compare the results with the VAR model in HWIII."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b9816b-aca5-483a-ad61-39faba146bfa",
   "metadata": {},
   "source": [
    "### 1. Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b1b83-809f-4e33-ac28-8c101808a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2  # Two-dimensional time series data\n",
    "hidden_size = 5  # Number of nodes in the hidden layer\n",
    "output_size = 2  # Output size (regression)\n",
    "\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0489d1aa-55eb-4099-8f72-63b3adc75b55",
   "metadata": {},
   "source": [
    "### 2. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515c1831-c324-484a-a680-4bca15716b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the time series data\n",
    "train_data = df_gr[['umply_gr', 'pop_gr']].iloc[:split_point]\n",
    "test_data = df_gr[['umply_gr', 'pop_gr']].iloc[split_point:]\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "train_data_torch = torch.FloatTensor(train_data.values).view(-1, 2)\n",
    "test_data_torch = torch.FloatTensor(test_data.values).view(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb20bc-6e10-45e5-8637-98a4e5569f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(train_data_torch)\n",
    "    loss = criterion(outputs, train_data_torch)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 1000 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b2f3fd-7474-4f39-b5db-e6addc0c0560",
   "metadata": {},
   "source": [
    "### 3. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d92985-5e9d-461a-aabc-a13295dfe482",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize an array to store the forecasted values\n",
    "    forecasted_values = []\n",
    "    true_values = []\n",
    "\n",
    "    # Iterate through the test data one step at a time\n",
    "    for i in range(len(test_data_torch) - 1):\n",
    "        input_step = test_data_torch[:i+1]  # Include data up to the current step\n",
    "        output_step = model(input_step)\n",
    "        forecasted_values.append(output_step[-1].tolist())  # Take the last prediction\n",
    "\n",
    "    # Convert the forecasted values and true values to a PyTorch tensor\n",
    "    forecasted_values = [list(row) for row in zip(*forecasted_values)]\n",
    "    forecasted_umply_torch = torch.Tensor(forecasted_values[0])\n",
    "    forecasted_pop_torch = torch.Tensor(forecasted_values[1])\n",
    "\n",
    "    true_values = [list(row) for row in zip(*test_data_torch)]\n",
    "    true_umply_torch = torch.Tensor(true_values[0])\n",
    "    true_pop_torch = torch.Tensor(true_values[1])\n",
    "\n",
    "    # Reshape the forecasted values tensor to match the shape of the target data\n",
    "    forecasted_umply_torch = forecasted_umply_torch.view(-1, 1)\n",
    "    forecasted_pop_torch = forecasted_pop_torch.view(-1, 1)\n",
    "    true_umply_torch = true_umply_torch.view(-1, 1)\n",
    "    true_pop_torch = true_pop_torch.view(-1, 1)\n",
    "\n",
    "    # Calculate the MSE for the one-step-ahead forecast\n",
    "    mse_umply = criterion(forecasted_umply_torch, true_umply_torch[1:])\n",
    "    mse_pop = criterion(forecasted_pop_torch, true_pop_torch[1:])\n",
    "    print(f'\\nMean Squared Error for umply: {mse_umply.item():.4f}')\n",
    "    print(f'\\nMean Squared Error for pop: {mse_pop.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa66f05-a96b-404b-b338-45a671691858",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(true_umply_torch[1:], label='True Values', marker='o')\n",
    "plt.plot(forecasted_umply_torch, label='Forecasted Values', linestyle='dashed', marker='o')\n",
    "plt.title('umply 1-Step-Ahead Expanding-Window Forecast')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d6779f-ea0c-48c9-8361-f6a072329a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(true_pop_torch[1:], label='True Values', marker='o')\n",
    "plt.plot(forecasted_pop_torch, label='Forecasted Values', linestyle='dashed', marker='o')\n",
    "plt.title('pop 1-Step-Ahead Expanding-Window Forecast')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f4852-963f-49b7-8378-00af650356c4",
   "metadata": {},
   "source": [
    "### 4. Compare with VAR(2)\n",
    "Note: For details about the VAR(2) model, please refer to HWIII_analysis_liu.rmd. Here I only quote the results.\n",
    "\n",
    "RMSFE: \n",
    "\n",
    "NN model: umply_gr: 0.0016, pop_gr: 0.0000;\n",
    "\n",
    "ARIMA model: umply_gr: 0.1413, pop_gr: 0.0085.\n",
    "\n",
    "NN model has again smaller RMSFEs. The reasons are similar to 1-dimensional data in Section I."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e16f89d-7aad-4d0d-a6db-4df04e8bfe10",
   "metadata": {},
   "source": [
    "## III. BONUS: Estimate with LSTM\n",
    "In this section, I estimate and forecast umply_gr with simpleLSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9e33c1-9d04-4886-99f6-e65eda324fbf",
   "metadata": {},
   "source": [
    "### 1. Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ffb5f-8742-47ec-8df4-85389cf83031",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # Take the output from the last time step\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f3221-5a0c-474d-8eaa-1c980a5efcbc",
   "metadata": {},
   "source": [
    "### 2. Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acf83b7-b696-43a3-8407-6e6c35c66bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, loss function, and optimizer\n",
    "input_size = 1\n",
    "hidden_size = 5\n",
    "output_size = 1\n",
    "\n",
    "model = SimpleLSTM(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e549d0c9-04df-4e6a-928a-2b4d23614242",
   "metadata": {},
   "source": [
    "### 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c25cd-7e16-4e82-95c0-3602095efe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the split point based on the length of the DataFrame\n",
    "split_point = int(0.8 * len(df_gr))\n",
    "\n",
    "# Split the time series data\n",
    "train_data = df_gr['umply_gr'].iloc[:split_point]\n",
    "test_data = df_gr['umply_gr'].iloc[split_point:]\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "train_data_torch = torch.FloatTensor(train_data.values).view(1, -1, 1)\n",
    "test_data_torch = torch.FloatTensor(test_data.values).view(1, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b619664-da13-4f4f-9135-4f8a94e7fd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(train_data_torch)\n",
    "    loss = criterion(outputs, train_data_torch)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb110351-6e2d-4eb5-b3a4-68f430f3c265",
   "metadata": {},
   "source": [
    "### 4. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b1df64-7ee0-4f36-90c4-3706679b2705",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize an array to store the forecasted values\n",
    "    forecasted_values = []\n",
    "\n",
    "    # Iterate through the test data one step at a time\n",
    "    for i in range(len(test_data_torch)):\n",
    "        input_step = test_data_torch[:i+1]  # Add both batch_size and sequence_length dimensions\n",
    "        output_step = model(input_step)\n",
    "        last_prediction = output_step[:, -1].item()  # Access the last prediction\n",
    "        forecasted_values.append(last_prediction)\n",
    "\n",
    "    # Convert the forecasted values to a PyTorch tensor\n",
    "    forecasted_values_tensor = torch.Tensor(forecasted_values)\n",
    "\n",
    "    # Reshape the forecasted values tensor to match the shape of the target data\n",
    "    forecasted_values_tensor = forecasted_values_tensor.view(-1, 1)\n",
    "\n",
    "    # Calculate the MSE for the one-step-ahead forecast\n",
    "    mse_one_step_ahead = criterion(forecasted_values_tensor, test_data_torch)\n",
    "    print(f'\\nMean Squared Error for One-Step-Ahead Forecast: {mse_one_step_ahead.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
